{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size/epoch count/image size\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "IMG_HEIGHT = 185\n",
    "IMG_WIDTH = 259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get the label for a particular car\n",
    "@tf.function\n",
    "def get_label(file_path):\n",
    "    # convert path to list of components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # the second part is the model_id\n",
    "    model_id = parts[2]\n",
    "    category = '0'\n",
    "    f_label = open(\"D:/AutoLearn/Vehicle Data Set/data/misc/attributes.txt\") # contains all of the image attributes sorted by model_id\n",
    "    for line in f_label:\n",
    "        values = line.split()\n",
    "        if (values[0] == model_id): # the first value in each line is the model_id\n",
    "            category = values[5] # classification label is at the end of each line in the 6th position\n",
    "    f_label.close()\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve and return a resized image\n",
    "@tf.function\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process both the image and label from the file path\n",
    "@tf.function\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'D:/AutoLearn/Vehicle Data Set/data/train_test_split/classification/train.txt'\n",
    "test_file = 'D:/AutoLearn/Vehicle Data Set/data/train_test_split/classification/test.txt'\n",
    "train_images_array = []\n",
    "test_images_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move file locations to array\n",
    "with open(train_file) as my_file_train:\n",
    "    count = 0;\n",
    "    for line in my_file_train:\n",
    "        train_images_array.append(\"Vehicle Data Set/data/image/\" + line)\n",
    "        count += 1\n",
    "\n",
    "with open(test_file) as my_file_test:\n",
    "    count = 0\n",
    "    for line in my_file_test:\n",
    "        test_images_array.append(\"Vehicle Data Set/data/image/\" + line)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = len(train_images_array)\n",
    "total_test = len(test_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into a tensorflow dataset object\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_images_array)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into a dataset map with labels included\n",
    "labeled_training_ds = train_ds.map(process_path, num_parallel_calls = tf.data.experimental.AUTOTUNE) \n",
    "labeled_testing_ds = test_ds.map(process_path, num_parallel_calls = tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "#validation_image_generator = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "###### problem lies here - cant use flow from directory ######\n",
    "#train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           #directory=train_dir,\n",
    "                                                           #target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           #class_mode='binary')\n",
    "\n",
    "#val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              #directory=validation_dir,\n",
    "                                                              #target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              #class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Convolutions/pooling\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit_generator(\n",
    "#    train_data_gen,\n",
    "#    steps_per_epoch=total_train // batch_size,\n",
    "#    epochs=epochs,\n",
    "#    validation_data=val_data_gen,\n",
    "#    validation_steps=total_val // batch_size\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = prepare_for_training(labeled_training_ds)\n",
    "\n",
    "image_batch, label_batch = next(iter(training_ds))\n",
    "\n",
    "\n",
    "model.fit(training_ds)\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
